{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing All Binary Models for Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_features=pd.read_csv('train_features.csv')\n",
    "tr_labels=pd.read_csv('train_labels.csv')\n",
    "\n",
    "te_features=pd.read_csv('test_features.csv')\n",
    "te_labels=pd.read_csv('test_labels.csv')\n",
    "\n",
    "val_features=pd.read_csv('val_features.csv')\n",
    "val_labels=pd.read_csv('val_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'SVM': SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
       "     probability=False, random_state=None, shrinking=True, tol=0.001,\n",
       "     verbose=False),\n",
       " 'MLP': MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "               beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "               hidden_layer_sizes=(50,), learning_rate='invscaling',\n",
       "               learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "               momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "               power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "               tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "               warm_start=False),\n",
       " 'RF': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=8, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                        n_jobs=None, oob_score=False, random_state=None,\n",
       "                        verbose=0, warm_start=False),\n",
       " 'GB': GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                            learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                            max_features=None, max_leaf_nodes=None,\n",
       "                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                            min_samples_leaf=1, min_samples_split=2,\n",
       "                            min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                            n_iter_no_change=None, presort='deprecated',\n",
       "                            random_state=None, subsample=1.0, tol=0.0001,\n",
       "                            validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False),\n",
       " 'KNN': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                      metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                      weights='uniform'),\n",
       " 'GNB': GaussianNB(priors=None, var_smoothing=1e-09),\n",
       " 'DT': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                        max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                        random_state=None, splitter='best')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {}\n",
    "for mdl in ['LR', 'SVM', 'MLP', 'RF', 'GB', 'KNN', 'GNB', 'DT']:\n",
    "    models[mdl]=joblib.load('{}_model.pkl'.format(mdl))\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, features, labels):\n",
    "    start=time()\n",
    "    pred=model.predict(features)\n",
    "    end=time()\n",
    "    accuracy = round(accuracy_score(labels, pred), 3)\n",
    "    precision = round(precision_score(labels, pred), 3)\n",
    "    recall = round(recall_score(labels, pred), 3)\n",
    "    print('{} --Accuracy: {} / Precision:{}/Recall:{}/Latency:{}ms'.format(name, accuracy, precision,recall, round(end-start),4))\n",
    "   # or\n",
    "    print(classification_report(labels, pred))\n",
    "    print(confusion_matrix(labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR --Accuracy: 0.816 / Precision:0.831/Recall:0.711/Latency:0ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       103\n",
      "           1       0.83      0.71      0.77        76\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.80      0.81       179\n",
      "weighted avg       0.82      0.82      0.81       179\n",
      "\n",
      "[[92 11]\n",
      " [22 54]]\n",
      "SVM --Accuracy: 0.804 / Precision:0.902/Recall:0.605/Latency:0ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85       103\n",
      "           1       0.90      0.61      0.72        76\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.83      0.78      0.79       179\n",
      "weighted avg       0.82      0.80      0.80       179\n",
      "\n",
      "[[98  5]\n",
      " [30 46]]\n",
      "MLP --Accuracy: 0.827 / Precision:0.846/Recall:0.724/Latency:0ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       103\n",
      "           1       0.85      0.72      0.78        76\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.83      0.81      0.82       179\n",
      "weighted avg       0.83      0.83      0.82       179\n",
      "\n",
      "[[93 10]\n",
      " [21 55]]\n",
      "RF --Accuracy: 0.81 / Precision:0.839/Recall:0.684/Latency:0ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.85       103\n",
      "           1       0.84      0.68      0.75        76\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.82      0.79      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n",
      "[[93 10]\n",
      " [24 52]]\n",
      "GB --Accuracy: 0.816 / Precision:0.864/Recall:0.671/Latency:0ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85       103\n",
      "           1       0.86      0.67      0.76        76\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.83      0.80      0.80       179\n",
      "weighted avg       0.82      0.82      0.81       179\n",
      "\n",
      "[[95  8]\n",
      " [25 51]]\n",
      "KNN --Accuracy: 0.81 / Precision:0.904/Recall:0.618/Latency:0ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85       103\n",
      "           1       0.90      0.62      0.73        76\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.84      0.78      0.79       179\n",
      "weighted avg       0.83      0.81      0.80       179\n",
      "\n",
      "[[98  5]\n",
      " [29 47]]\n",
      "GNB --Accuracy: 0.827 / Precision:0.8/Recall:0.789/Latency:0ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       103\n",
      "           1       0.80      0.79      0.79        76\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.82      0.82      0.82       179\n",
      "weighted avg       0.83      0.83      0.83       179\n",
      "\n",
      "[[88 15]\n",
      " [16 60]]\n",
      "DT --Accuracy: 0.821 / Precision:0.844/Recall:0.711/Latency:0ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85       103\n",
      "           1       0.84      0.71      0.77        76\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.83      0.81      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n",
      "[[93 10]\n",
      " [22 54]]\n"
     ]
    }
   ],
   "source": [
    "for name, mdl in models.items():\n",
    "    evaluate_model(name, mdl, val_features,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest --Accuracy: 0.809 / Precision:0.772/Recall:0.677/Latency:0ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       113\n",
      "           1       0.77      0.68      0.72        65\n",
      "\n",
      "    accuracy                           0.81       178\n",
      "   macro avg       0.80      0.78      0.79       178\n",
      "weighted avg       0.81      0.81      0.81       178\n",
      "\n",
      "[[100  13]\n",
      " [ 21  44]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model('Random Forest', models['RF'], te_features,te_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
